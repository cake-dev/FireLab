{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tempfile\n",
    "import warnings\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask_geopandas as dgpd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from scipy.fft import dst\n",
    "import tqdm\n",
    "import xarray as xr\n",
    "from dask.diagnostics import ProgressBar\n",
    "from rasterio.crs import CRS\n",
    "\n",
    "from raster_tools import Raster, Vector, open_vectors, clipping, zonal\n",
    "from raster_tools.dtypes import F32, U8, U16\n",
    "\n",
    "# Filter out warnings from dask_geopandas and dask\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", message=\".*initial implementation of Parquet.*\"\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", message=\".*Slicing is producing a large chunk.*\"\n",
    ")\n",
    "\n",
    "\n",
    "# Location for temporary storage\n",
    "TMP_LOC = \"/home/jake/FireLab/Project/data/temp/\"\n",
    "TMP_LOC2 = \"/home/jake/FireLab/Project/data/temp2/\"\n",
    "TMP_LOC3 = \"/home/jake/FireLab/Project/data/temp3/\"\n",
    "DATA_LOC = \"/home/jake/FireLab/Project/data/\"\n",
    "\n",
    "STATE = \"OR\"\n",
    "\n",
    "# Location of clipped DEM files\n",
    "DEM_DATA_DIR = pjoin(TMP_LOC, \"dem_data\")\n",
    "\n",
    "# location of feature data files\n",
    "FEATURE_DIR = pjoin(DATA_LOC, \"FeatureData\")\n",
    "EDNA_DIR = pjoin(DATA_LOC, \"terrain\")\n",
    "MTBS_DIR = pjoin(DATA_LOC, \"MTBS_Data\")\n",
    "VIIRS_DIR = pjoin(DATA_LOC, \"viirs_data\")\n",
    "\n",
    "PATHS = {\n",
    "    \"states\": pjoin(EDNA_DIR, \"state_borders/cb_2018_us_state_5m.shp\"),\n",
    "    \"dem\": pjoin(EDNA_DIR, \"us_orig_dem/us_orig_dem/orig_dem/hdr.adf\"),\n",
    "    \"dem_slope\": pjoin(EDNA_DIR, \"us_slope/us_slope/slope/hdr.adf\"),\n",
    "    \"dem_aspect\": pjoin(EDNA_DIR, \"us_aspect/aspect/hdr.adf\"),\n",
    "    \"dem_flow_acc\": pjoin(EDNA_DIR, \"us_flow_acc/us_flow_acc/flow_acc/hdr.adf\"),\n",
    "    \"gm_srad\": pjoin(FEATURE_DIR, \"gridmet/srad_1986_2020_weekly.nc\"),\n",
    "    \"gm_vpd\": pjoin(FEATURE_DIR, \"gridmet/vpd_1986_2020_weekly.nc\"),\n",
    "    \"aw_mat\": pjoin(FEATURE_DIR, \"adaptwest/Normal_1991_2020_MAT.tif\"),\n",
    "    \"aw_mcmt\": pjoin(FEATURE_DIR, \"adaptwest/Normal_1991_2020_MCMT.tif\"),\n",
    "    \"aw_mwmt\": pjoin(FEATURE_DIR, \"adaptwest/Normal_1991_2020_MWMT.tif\"),\n",
    "    \"aw_td\": pjoin(FEATURE_DIR, \"adaptwest/Normal_1991_2020_TD.tif\"),\n",
    "    \"dm_tmax\": pjoin(FEATURE_DIR, \"daymet/tmax_1986_2020.nc\"),\n",
    "    \"dm_tmin\": pjoin(FEATURE_DIR, \"daymet/tmin_1986_2020.nc\"),\n",
    "    \"biomass_afg\": pjoin(\n",
    "        FEATURE_DIR, \"biomass/biomass_afg_1986_2020_{}.nc\".format(STATE)\n",
    "    ),\n",
    "    \"biomass_pfg\": pjoin(\n",
    "        FEATURE_DIR, \"biomass/biomass_pfg_1986_2020_{}.nc\".format(STATE)\n",
    "    ),\n",
    "    \"landfire_fvt\": pjoin(\n",
    "        FEATURE_DIR, \"landfire/LF2020_FVT_200_CONUS/Tif/LC20_FVT_200.tif\"\n",
    "    ),\n",
    "    \"landfire_fbfm40\": pjoin(\n",
    "        FEATURE_DIR, \"landfire/LF2020_FBFM40_200_CONUS/Tif/LC20_F40_200.tif\"\n",
    "    ),\n",
    "    \"ndvi\": pjoin(FEATURE_DIR, \"ndvi/access/weekly/ndvi_1986_2020_weekavg.nc\"),\n",
    "    \"mtbs_root\": pjoin(MTBS_DIR, \"MTBS_BSmosaics/\"),\n",
    "    \"mtbs_perim\": pjoin(MTBS_DIR, \"mtbs_perimeter_data/mtbs_perims_DD.shp\"),\n",
    "    \"viirs_root\": VIIRS_DIR,\n",
    "    \"viirs_perim\": pjoin(VIIRS_DIR, \"viirs_perims_shapefile.shp\"),\n",
    "}\n",
    "YEARS = list(range(2018, 2021))\n",
    "GM_KEYS = list(filter(lambda x: x.startswith(\"gm_\"), PATHS))\n",
    "AW_KEYS = list(filter(lambda x: x.startswith(\"aw_\"), PATHS))\n",
    "DM_KEYS = list(filter(lambda x: x.startswith(\"dm_\"), PATHS))\n",
    "BIOMASS_KEYS = list(filter(lambda x: x.startswith(\"biomass_\"), PATHS))\n",
    "LANDFIRE_KEYS = list(filter(lambda x: x.startswith(\"landfire_\"), PATHS))\n",
    "NDVI_KEYS = list(filter(lambda x: x.startswith(\"ndvi\"), PATHS))\n",
    "DEM_KEYS = list(filter(lambda x: x.startswith(\"dem\"), PATHS))\n",
    "\n",
    "NC_KEYSET = set(GM_KEYS + DM_KEYS + BIOMASS_KEYS + NDVI_KEYS)\n",
    "TIF_KEYSET = [AW_KEYS, LANDFIRE_KEYS] \n",
    "\n",
    "MTBS_DF_PATH = pjoin(TMP_LOC, f\"{STATE}_mtbs.parquet\")\n",
    "MTBS_DF_PARQUET_PATH_NEW = pjoin(TMP_LOC, f\"{STATE}_mtbs_new.parquet\")\n",
    "MTBS_DF_TEMP_PATH = pjoin(TMP_LOC, f\"{STATE}_mtbs_temp.parquet\")\n",
    "MTBS_DF_TEMP_PATH_2 = pjoin(TMP_LOC, f\"{STATE}_mtbs_temp_2.parquet\")\n",
    "CHECKPOINT_1_PATH = pjoin(TMP_LOC, \"check1\")\n",
    "CHECKPOINT_2_PATH = pjoin(TMP_LOC, \"check2\")\n",
    "CHECKPOINT_3_PATH = pjoin(TMP_LOC, \"check3\")\n",
    "CHECKPOINT_4_PATH = pjoin(TMP_LOC, \"check4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hillshade(slope, aspect, azimuth=180, zenith=45):\n",
    "    # Convert angles from degrees to radians\n",
    "    azimuth_rad = np.radians(azimuth)\n",
    "    zenith_rad = np.radians(zenith)\n",
    "    slope_rad = np.radians(slope)\n",
    "    aspect_rad = np.radians(aspect)\n",
    "\n",
    "    # Calculate hillshade\n",
    "    shaded = np.sin(zenith_rad) * np.sin(slope_rad) + \\\n",
    "             np.cos(zenith_rad) * np.cos(slope_rad) * \\\n",
    "             np.cos(azimuth_rad - aspect_rad)\n",
    "    # scale to 0-255\n",
    "    shaded = 255 * (shaded + 1) / 2\n",
    "    # round hillshade to nearest integer\n",
    "    shaded = np.rint(shaded)\n",
    "    # convert to uint8\n",
    "    # Ensure non-finite values are not converted to int\n",
    "    # shaded = np.where(np.isfinite(shaded), shaded.astype(np.uint8), np.nan)\n",
    "    return shaded\n",
    "\n",
    "def hillshade_partition(df, zenith, azimuth):\n",
    "    # Apply the hillshade function to the slope and aspect columns\n",
    "    df['hillshade'] = hillshade(df['dem_slope'], df['dem_aspect'], azimuth, zenith)\n",
    "    return df\n",
    "\n",
    "def timestamp_to_year_part(df):\n",
    "    # Assuming 'ig_date' is the column with timestamp data\n",
    "    df['year'] = df['ig_date'].dt.year\n",
    "    return df\n",
    "\n",
    "def get_nc_var_name(ds, nc_feat_name):\n",
    "    # Find the data variable in a nc xarray.Dataset\n",
    "    if nc_feat_name.startswith(\"dm\"):\n",
    "        var_name = list(set(ds.keys()) - set([\"crs\", \"bnds\"]))[0] # for DAYMET ONLY!!\n",
    "    else:\n",
    "        var_name = list(set(ds.keys()) - set([\"crs\", \"day_bnds\"]))[0]\n",
    "    return var_name\n",
    "\n",
    "\n",
    "def netcdf_to_raster(path, date, nc_feature_name):\n",
    "    # This produces a Dataset. We need to grab the DataArray inside that\n",
    "    # contains the data of interest.\n",
    "    nc_ds = xr.open_dataset(path, chunks={\"day\": 1})#, decode_times=False)\n",
    "    if nc_feature_name == \"ndvi\":\n",
    "        nc_ds2 = nc_ds.drop_vars(\n",
    "        [\"latitude_bnds\", \"longitude_bnds\", \"time_bnds\"]\n",
    "        ).rio.write_crs(\"EPSG:5071\") # FOR NDVI ONLY!!\n",
    "    elif nc_feature_name.startswith(\"dm_\"):\n",
    "        nc_ds2 = nc_ds.rio.write_crs(\"EPSG:5071\")  # FOR DAYMET ONLY!!\n",
    "        # nc_ds = nc_ds.rio.write_crs(\n",
    "        #     nc_ds.coords[\"lambert_conformal_conic\"].spatial_ref\n",
    "        # )  # FOR DAYMET ONLY!!\n",
    "        nc_ds2 = nc_ds2.rename({\"lambert_conformal_conic\": \"crs\"})  # FOR DAYMET ONLY!!\n",
    "        nc_ds2 = nc_ds2.drop_vars([\"lat\", \"lon\", \"time_bnds\"])  # FOR DAYMET ONLY!!\n",
    "        nc_ds = None # FOR DAYMET ONLY!!\n",
    "        nc_ds2 = nc_ds2.rename_vars({\"x\": \"lon\", \"y\": \"lat\"})  # FOR DAYMET ONLY!!\n",
    "    else:\n",
    "        nc_ds2 = nc_ds.rio.write_crs(\"EPSG:5071\")\n",
    "\n",
    "    # Find variable name\n",
    "    var_name = get_nc_var_name(nc_ds2, nc_feature_name)\n",
    "    # print(f\"var_name: {var_name}\")\n",
    "    # Extract\n",
    "    var_da = nc_ds2[var_name]\n",
    "    # print(f\"{var_da = }\")\n",
    "    if nc_feature_name.startswith(\"gm_\"):\n",
    "        var_da = var_da.sel(day=date, method=\"nearest\") # for GM\n",
    "    else:\n",
    "        var_da = var_da.sel(time=date, method=\"nearest\") # for DM and BM and NDVI\n",
    "    if nc_feature_name.startswith(\"ndvi\"):\n",
    "        xrs = xr.DataArray(\n",
    "            var_da.data, dims=(\"y\", \"x\"), coords=(var_da.latitude.data, var_da.longitude.data)\n",
    "        ).expand_dims(\"band\") # FOR NDVI ONLY!!\n",
    "    else:\n",
    "        xrs = xr.DataArray(\n",
    "            var_da.data, dims=(\"y\", \"x\"), coords=(var_da.lat.data, var_da.lon.data)\n",
    "        ).expand_dims(\"band\") # For non-NDVI\n",
    "    xrs[\"band\"] = [1]\n",
    "    # Set CRS in raster compliant format\n",
    "    xrs = xrs.rio.write_crs(nc_ds2.crs.spatial_ref)\n",
    "    return Raster(xrs)\n",
    "\n",
    "\n",
    "def extract_nc_data(df, nc_name):\n",
    "    assert df.ig_date.unique().size == 1\n",
    "    # print(f\"{gm_name}: {df.columns = }, {len(df) = }\")\n",
    "    date = df.ig_date.values[0]\n",
    "    print(f\"{nc_name}: starting {date}\")\n",
    "    rs = netcdf_to_raster(PATHS[nc_name], date, nc_name)\n",
    "    bounds = gpd.GeoSeries(df.geometry).to_crs(rs.crs).total_bounds\n",
    "    rs = clipping.clip_box(rs, bounds)\n",
    "    if type(df) == pd.DataFrame:\n",
    "        df = gpd.GeoDataFrame(df)\n",
    "    feat = Vector(df, len(df))\n",
    "    rdf = (\n",
    "        zonal.extract_points_eager(feat, rs, skip_validation=True)\n",
    "        .drop(columns=[\"band\"])\n",
    "        .rename(columns={\"extracted\": nc_name})\n",
    "        .compute()\n",
    "    )\n",
    "    df[nc_name].values[:] = rdf[nc_name].values\n",
    "    # print(f\"{nc_name}: finished {date}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_state_dem_path(dem_key, state):\n",
    "    return pjoin(DEM_DATA_DIR, f\"{state}_{dem_key}.tif\")\n",
    "\n",
    "\n",
    "def extract_dem_data(df, key):\n",
    "    state = df.state.values[0]\n",
    "    path = get_state_dem_path(key, state)\n",
    "    rs = Raster(path)\n",
    "    if type(df) == pd.DataFrame:\n",
    "        df = gpd.GeoDataFrame(df)\n",
    "    feat = Vector(df, len(df))\n",
    "    rdf = (\n",
    "        zonal.extract_points_eager(feat, rs, skip_validation=True)\n",
    "        .drop(columns=[\"band\"])\n",
    "        .compute()\n",
    "    )\n",
    "    df[key].values[:] = rdf.extracted.values\n",
    "    return df\n",
    "\n",
    "def extract_tif_data(df, key):\n",
    "    state = df.state.values[0]\n",
    "    path = PATHS[key]\n",
    "    rs = Raster(path)\n",
    "    if type(df) == pd.DataFrame:\n",
    "        df = gpd.GeoDataFrame(df)\n",
    "    feat = Vector(df, len(df))\n",
    "    rdf = (\n",
    "        zonal.extract_points_eager(feat, rs, skip_validation=True)\n",
    "        .drop(columns=[\"band\"])\n",
    "        .compute()\n",
    "    )\n",
    "    df[key].values[:] = rdf.extracted.values\n",
    "    return df\n",
    "\n",
    "\n",
    "def partition_extract_nc(df, key):\n",
    "    # This func wraps extract_nc_data. It groups the partition in to sub\n",
    "    # dataframes with the same date and then applies extract_nc_data to\n",
    "    # each and reassembles the results into an output dataframe.\n",
    "    parts = []\n",
    "    for group in df.groupby(\"ig_date\", sort=True):\n",
    "        _, gdf = group\n",
    "        parts.append(extract_nc_data(gdf, key))\n",
    "    return pd.concat(parts)\n",
    "\n",
    "def partition_extract_tif(df, key):\n",
    "    # This func wraps extract_tif_data. It groups the partition in to sub\n",
    "    # dataframes with the same date and then applies extract_tif_data to\n",
    "    # each and reassembles the results into an output dataframe.\n",
    "    parts = []\n",
    "    for group in df.groupby(\"ig_date\", sort=True):\n",
    "        _, gdf = group\n",
    "        parts.append(extract_tif_data(gdf, key))\n",
    "    return pd.concat(parts)\n",
    "\n",
    "def clip_and_save_dem_rasters(keys, paths, feature, state):\n",
    "    feature = feature.compute()\n",
    "    for k in tqdm.tqdm(keys, ncols=80, desc=\"DEM Clipping\"):\n",
    "        path = paths[k]\n",
    "        out_path = get_state_dem_path(k, state)\n",
    "        if os.path.exists(out_path):\n",
    "            continue\n",
    "        rs = Raster(path)\n",
    "        (bounds,) = dask.compute(feature.to_crs(rs.crs).total_bounds)\n",
    "        crs = clipping.clip_box(rs, bounds)\n",
    "        crs.save(out_path)\n",
    "\n",
    "\n",
    "def build_mtbs_year_df(path, perims_df, state_label):\n",
    "    rs = Raster(path)\n",
    "    dfs = []\n",
    "    for grp in perims_df.groupby(\"Ig_Date\"):\n",
    "        date, perim = grp\n",
    "        df = (\n",
    "            clipping.clip(perim, rs)\n",
    "            .to_vector()\n",
    "            .rename(columns={\"value\": \"mtbs\"})\n",
    "            .drop(columns=[\"band\", \"row\", \"col\"])\n",
    "            .assign(state=state_label, ig_date=date)\n",
    "            .astype({\"mtbs\": U8})\n",
    "        )\n",
    "        dfs.append(df)\n",
    "    return dd.concat(dfs)\n",
    "\n",
    "\n",
    "def _build_mtbs_df(\n",
    "    years, year_to_mtbs_file, year_to_perims, state, working_dir\n",
    "):\n",
    "    dfs = []\n",
    "    it = tqdm.tqdm(years, ncols=80, desc=\"MTBS\")\n",
    "    for y in it:\n",
    "        mtbs_path = year_to_mtbs_file[y]\n",
    "        if not os.path.exists(mtbs_path):\n",
    "            it.write(f\"No data for {y}\")\n",
    "            continue\n",
    "        perims = year_to_perims[y]\n",
    "        ydf = build_mtbs_year_df(mtbs_path, perims, state)\n",
    "        ypath = pjoin(working_dir, str(y))\n",
    "        ydf.compute().to_parquet(ypath)\n",
    "        ydf = dgpd.read_parquet(ypath)\n",
    "        dfs.append(ydf)\n",
    "    return dd.concat(dfs)\n",
    "\n",
    "\n",
    "def build_mtbs_df(\n",
    "    years, year_to_mtbs_file, year_to_perims, state, out_path, tmp_loc=TMP_LOC\n",
    "):\n",
    "    print(\"Building mtbs df\")\n",
    "    with tempfile.TemporaryDirectory(dir=tmp_loc) as working_dir:\n",
    "        df = _build_mtbs_df(\n",
    "            years, year_to_mtbs_file, year_to_perims, state, working_dir\n",
    "        )\n",
    "        print(\"built df: \", df.head())\n",
    "        with ProgressBar():\n",
    "            df.to_parquet(out_path)\n",
    "    return dgpd.read_parquet(out_path)\n",
    "\n",
    "\n",
    "def add_columns_to_df(\n",
    "    df,\n",
    "    columns,\n",
    "    part_func,\n",
    "    out_path,\n",
    "    col_type=F32,\n",
    "    col_default=np.nan,\n",
    "    part_func_args=(),\n",
    "    # tmp_loc=TMP_LOC,\n",
    "    tmp_loc=TMP_LOC2,\n",
    "    parallel=True,\n",
    "):\n",
    "    print(f\"Adding columns: {columns}\")\n",
    "    print('Existing columns: ', df.columns)\n",
    "    # Add columns\n",
    "    expanded_df = df.assign(**{c: col_type.type(col_default) for c in columns})\n",
    "    # show expanded_df\n",
    "    print('Expanded columns: ', expanded_df.columns)\n",
    "    with tempfile.TemporaryDirectory(dir=tmp_loc) as working_dir:\n",
    "        # Save to disk before applying partition function. to_parquet() has a\n",
    "        # chance of segfaulting and that chance goes WAY up after adding\n",
    "        # columns and then mapping a function to partitions. Saving to disk\n",
    "        # before mapping keeps the odds low.\n",
    "        path = pjoin(working_dir, \"expanded\")\n",
    "        print(expanded_df.head())\n",
    "        # reset the index to fix keyerror not in index\n",
    "        # expanded_df = expanded_df.reset_index()\n",
    "        expanded_df.to_parquet(path)\n",
    "\n",
    "        expanded_df = dgpd.read_parquet(path)\n",
    "        meta = expanded_df._meta.copy()\n",
    "        for c in columns:\n",
    "            expanded_df = expanded_df.map_partitions(\n",
    "                part_func, c, *part_func_args, meta=meta\n",
    "            )\n",
    "\n",
    "        if parallel:\n",
    "            with ProgressBar():\n",
    "                expanded_df.to_parquet(out_path)\n",
    "        else:\n",
    "            # Save parts in serial and then assemble into single dataframe\n",
    "            with tempfile.TemporaryDirectory(dir=tmp_loc) as part_dir:\n",
    "                dfs = []\n",
    "                for i, part in enumerate(expanded_df.partitions):\n",
    "                    # Save part i\n",
    "                    part_path = pjoin(part_dir, f\"part{i:04}\")\n",
    "                    with ProgressBar():\n",
    "                        part.compute().to_parquet(part_path)\n",
    "                    # Save paths for opening with dask_geopandas later. Avoid\n",
    "                    # opening more dataframes in this loop as doing so will\n",
    "                    # likely cause a segfault. I have no idea why.\n",
    "                    dfs.append(part_path)\n",
    "                dfs = [dgpd.read_parquet(p) for p in dfs]\n",
    "                # Assemble and save to final output location\n",
    "                expanded_df = dd.concat(dfs)\n",
    "                with ProgressBar():\n",
    "                    expanded_df.to_parquet(out_path)\n",
    "    return dgpd.read_parquet(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/.conda/envs/firelab/lib/python3.9/site-packages/gribapi/__init__.py:23: UserWarning: ecCodes 2.31.0 or higher is recommended. You are running version 2.24.2\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# open biomass afg data\n",
    "def open_biomass_afg_data():\n",
    "    # Open biomass afg data\n",
    "    biomass_afg = xr.open_dataset(PATHS[\"biomass_afg\"])\n",
    "    # Get the data variable name\n",
    "    var_name = get_nc_var_name(biomass_afg, \"biomass_afg\")\n",
    "    # Extract the data variable\n",
    "    var_da = biomass_afg[var_name]\n",
    "    return var_da\n",
    "\n",
    "# open daymet tmax data\n",
    "def open_daymet_tmax_data():\n",
    "    # Open daymet tmax data\n",
    "    daymet_tmax = xr.open_dataset(PATHS[\"dm_tmax\"])\n",
    "    # Get the data variable name\n",
    "    var_name = get_nc_var_name(daymet_tmax, \"dm_tmax\")\n",
    "    # Extract the data variable\n",
    "    var_da = daymet_tmax[var_name]\n",
    "    return var_da\n",
    "\n",
    "bmafg = open_biomass_afg_data()\n",
    "dmtmax = open_daymet_tmax_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;Band1&#x27; (time: 35, lat: 16216, lon: 31615)&gt;\n",
       "[17943409400 values with dtype=float32]\n",
       "Coordinates:\n",
       "  * time     (time) float64 1.986e+07 1.987e+07 1.988e+07 ... 2.019e+07 2.02e+07\n",
       "  * lon      (lon) float64 -124.8 -124.8 -124.8 -124.8 ... -116.3 -116.3 -116.3\n",
       "  * lat      (lat) float64 41.86 41.86 41.86 41.86 ... 46.23 46.23 46.23 46.23\n",
       "Attributes:\n",
       "    long_name:     GDAL Band Number 1\n",
       "    grid_mapping:  crs</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'Band1'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 35</li><li><span class='xr-has-index'>lat</span>: 16216</li><li><span class='xr-has-index'>lon</span>: 31615</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-e26d2605-fc26-40f5-af1e-99561fa65e3d' class='xr-array-in' type='checkbox' checked><label for='section-e26d2605-fc26-40f5-af1e-99561fa65e3d' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>...</span></div><div class='xr-array-data'><pre>[17943409400 values with dtype=float32]</pre></div></div></li><li class='xr-section-item'><input id='section-7ff39958-2e05-4182-9aba-b4eac0b0e7f2' class='xr-section-summary-in' type='checkbox'  checked><label for='section-7ff39958-2e05-4182-9aba-b4eac0b0e7f2' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>1.986e+07 1.987e+07 ... 2.02e+07</div><input id='attrs-996a1ead-117e-48d4-bf9c-f0bbadb6dc89' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-996a1ead-117e-48d4-bf9c-f0bbadb6dc89' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-095232d2-c2e0-4d68-a4fe-2b721aad4160' class='xr-var-data-in' type='checkbox'><label for='data-095232d2-c2e0-4d68-a4fe-2b721aad4160' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>units :</span></dt><dd>day as %Y%m%d.%f</dd><dt><span>calendar :</span></dt><dd>proleptic_gregorian</dd><dt><span>axis :</span></dt><dd>T</dd></dl></div><div class='xr-var-data'><pre>array([19860101., 19870101., 19880101., 19890101., 19900101., 19910101.,\n",
       "       19920101., 19930101., 19940101., 19950101., 19960101., 19970101.,\n",
       "       19980101., 19990101., 20000101., 20010101., 20020101., 20030101.,\n",
       "       20040101., 20050101., 20060101., 20070101., 20080101., 20090101.,\n",
       "       20100101., 20110101., 20120101., 20130101., 20140101., 20150101.,\n",
       "       20160101., 20170101., 20180101., 20190101., 20200101.])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-124.8 -124.8 ... -116.3 -116.3</div><input id='attrs-eaa9f50b-eb07-454d-ad56-d0aa1cad969c' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-eaa9f50b-eb07-454d-ad56-d0aa1cad969c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9888b260-2e85-418e-b8d6-8a8c6d27b962' class='xr-var-data-in' type='checkbox'><label for='data-9888b260-2e85-418e-b8d6-8a8c6d27b962' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>projection_x_coordinate</dd><dt><span>long_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>axis :</span></dt><dd>X</dd></dl></div><div class='xr-var-data'><pre>array([-124.849969, -124.8497  , -124.84943 , ..., -116.330706, -116.330437,\n",
       "       -116.330167])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>41.86 41.86 41.86 ... 46.23 46.23</div><input id='attrs-2235539b-f548-49b1-82f9-f827679150d2' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-2235539b-f548-49b1-82f9-f827679150d2' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6b7ecf4a-dc31-417d-b51b-d54f046a2d24' class='xr-var-data-in' type='checkbox'><label for='data-6b7ecf4a-dc31-417d-b51b-d54f046a2d24' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>projection_y_coordinate</dd><dt><span>long_name :</span></dt><dd>latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>axis :</span></dt><dd>Y</dd></dl></div><div class='xr-var-data'><pre>array([41.86019 , 41.860459, 41.860729, ..., 46.229505, 46.229775, 46.230044])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-bae2e242-86ca-4571-a0a0-e9585c444c7a' class='xr-section-summary-in' type='checkbox'  ><label for='section-bae2e242-86ca-4571-a0a0-e9585c444c7a' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-49c107a9-5673-43df-89db-fbcdde8295bb' class='xr-index-data-in' type='checkbox'/><label for='index-49c107a9-5673-43df-89db-fbcdde8295bb' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([19860101.0, 19870101.0, 19880101.0, 19890101.0, 19900101.0, 19910101.0,\n",
       "       19920101.0, 19930101.0, 19940101.0, 19950101.0, 19960101.0, 19970101.0,\n",
       "       19980101.0, 19990101.0, 20000101.0, 20010101.0, 20020101.0, 20030101.0,\n",
       "       20040101.0, 20050101.0, 20060101.0, 20070101.0, 20080101.0, 20090101.0,\n",
       "       20100101.0, 20110101.0, 20120101.0, 20130101.0, 20140101.0, 20150101.0,\n",
       "       20160101.0, 20170101.0, 20180101.0, 20190101.0, 20200101.0],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;time&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lon</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-3c232919-a7f7-4afe-9b68-ecc5a7cb4fbe' class='xr-index-data-in' type='checkbox'/><label for='index-3c232919-a7f7-4afe-9b68-ecc5a7cb4fbe' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([-124.84996922784879, -124.84969973326355, -124.84943023867832,\n",
       "       -124.84916074409308, -124.84889124950784,  -124.8486217549226,\n",
       "       -124.84835226033738, -124.84808276575214,  -124.8478132711669,\n",
       "       -124.84754377658167,\n",
       "       ...\n",
       "       -116.33259286146955, -116.33232336688431, -116.33205387229907,\n",
       "       -116.33178437771383,  -116.3315148831286, -116.33124538854337,\n",
       "       -116.33097589395813, -116.33070639937289, -116.33043690478766,\n",
       "       -116.33016741020242],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;lon&#x27;, length=31615))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lat</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-234f34e9-9536-46eb-804b-109e7f39d9b4' class='xr-index-data-in' type='checkbox'/><label for='index-234f34e9-9536-46eb-804b-109e7f39d9b4' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([41.860189682807736,  41.86045917739297,  41.86072867197821,\n",
       "        41.86099816656344,  41.86126766114868,  41.86153715573391,\n",
       "       41.861806650319146, 41.862076144904385,  41.86234563948962,\n",
       "        41.86261513407486,\n",
       "       ...\n",
       "        46.22761893114003,  46.22788842572526, 46.228157920310494,\n",
       "       46.228427414895734, 46.228696909480966, 46.228966404066206,\n",
       "        46.22923589865144,  46.22950539323668,  46.22977488782191,\n",
       "        46.23004438240715],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;lat&#x27;, length=16216))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-516cca5d-9539-481b-a08e-8ffa048f057d' class='xr-section-summary-in' type='checkbox'  checked><label for='section-516cca5d-9539-481b-a08e-8ffa048f057d' class='xr-section-summary' >Attributes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>GDAL Band Number 1</dd><dt><span>grid_mapping :</span></dt><dd>crs</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'Band1' (time: 35, lat: 16216, lon: 31615)>\n",
       "[17943409400 values with dtype=float32]\n",
       "Coordinates:\n",
       "  * time     (time) float64 1.986e+07 1.987e+07 1.988e+07 ... 2.019e+07 2.02e+07\n",
       "  * lon      (lon) float64 -124.8 -124.8 -124.8 -124.8 ... -116.3 -116.3 -116.3\n",
       "  * lat      (lat) float64 41.86 41.86 41.86 41.86 ... 46.23 46.23 46.23 46.23\n",
       "Attributes:\n",
       "    long_name:     GDAL Band Number 1\n",
       "    grid_mapping:  crs"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmafg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN ###\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if 1:\n",
    "        # State borders\n",
    "        print(\"Loading state borders\")\n",
    "        stdf = open_vectors(PATHS[\"states\"], 0).data.to_crs(\"EPSG:5071\")\n",
    "        states = {st: stdf[stdf.STUSPS == st].geometry for st in list(stdf.STUSPS)}\n",
    "        state_shape = states[STATE]\n",
    "        states = None\n",
    "        stdf = None\n",
    "\n",
    "        # MTBS Perimeters\n",
    "        print(\"Loading MTBS perimeters\")\n",
    "        perimdf = open_vectors(PATHS[\"mtbs_perim\"]).data.to_crs(\"EPSG:5071\")\n",
    "        state_fire_perims = perimdf.clip(state_shape.compute())\n",
    "        state_fire_perims = (\n",
    "            state_fire_perims.assign(\n",
    "                Ig_Date=lambda frame: dd.to_datetime(\n",
    "                    frame.Ig_Date, format=\"%Y-%m-%d\"\n",
    "                )\n",
    "            )\n",
    "            .sort_values(\"Ig_Date\")\n",
    "            .compute()\n",
    "        )\n",
    "        state_fire_perims = state_fire_perims[state_fire_perims.Ig_Date.dt.year.between(2018, 2020)]\n",
    "        year_to_perims = {\n",
    "            y: state_fire_perims[state_fire_perims.Ig_Date.dt.year == y]\n",
    "            for y in YEARS\n",
    "        }\n",
    "        state_fire_perims = None\n",
    "\n",
    "        year_to_mtbs_file = {\n",
    "            y: pjoin(PATHS[\"mtbs_root\"], f\"mtbs_{STATE}_{y}.tif\")\n",
    "            for y in YEARS\n",
    "        }\n",
    "\n",
    "        # print(year_to_mtbs_file)\n",
    "\n",
    "\n",
    "    if 0:\n",
    "        # code below for creating a new dataset for a new state / region\n",
    "        df = build_mtbs_df(\n",
    "            YEARS,\n",
    "            year_to_mtbs_file,\n",
    "            year_to_perims,\n",
    "            STATE,\n",
    "            out_path=CHECKPOINT_1_PATH,\n",
    "        )\n",
    "        clip_and_save_dem_rasters(DEM_KEYS, PATHS, state_shape, STATE)\n",
    "        df = add_columns_to_df(\n",
    "            df,\n",
    "            DEM_KEYS,\n",
    "            extract_dem_data,\n",
    "            CHECKPOINT_1_PATH,\n",
    "            # Save results in serial to avoid segfaulting. Something about the\n",
    "            # dem computations makes segfaults extremely likely when saving\n",
    "            # The computations require a lot of memory which may be what\n",
    "            # triggers the fault.\n",
    "            parallel=False,\n",
    "        )\n",
    "        df = df.repartition(partition_size=\"100MB\").reset_index(drop=True)\n",
    "        print(\"Repartitioning\")\n",
    "        with ProgressBar():\n",
    "            df.to_parquet(CHECKPOINT_2_PATH) \n",
    "        df = None\n",
    "\n",
    "    if 0:\n",
    "        # code below used to add new features to the dataset\n",
    "        with ProgressBar():\n",
    "            df = dgpd.read_parquet(CHECKPOINT_1_PATH)\n",
    "\n",
    "        print(\"Columns: \", df.columns)\n",
    "\n",
    "        # add biomass features\n",
    "        for biomass_name in BIOMASS_KEYS:\n",
    "            print(f\"Adding {biomass_name}\")\n",
    "            df = add_columns_to_df(\n",
    "                df, [biomass_name], partition_extract_nc, CHECKPOINT_3_PATH, parallel=False\n",
    "            )\n",
    "        # add hillshade and year columns\n",
    "        df_meta = df._meta.copy()\n",
    "        df = df.assign(hillshade=U8.type(0))\n",
    "        df = df.map_partitions(hillshade_partition, 45, 180, meta=df_meta)\n",
    "        df = df.assign(year=U16.type(0))\n",
    "        df = df.map_partitions(timestamp_to_year_part, meta=df_meta)\n",
    "        print(\"Columns: \", df.columns)\n",
    "        df = df.repartition(partition_size=\"100MB\").reset_index(drop=True)\n",
    "        print(\"Repartitioning\")\n",
    "        df = df.compute()\n",
    "        with ProgressBar():\n",
    "            df.to_parquet(MTBS_DF_TEMP_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
