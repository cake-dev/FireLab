12/05:

---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
Cell In[2], line 96
     94 df = df.map_partitions(timestamp_to_year_part, meta=df_meta)
     95 print("Columns: ", df.columns)
---> 96 df = df.repartition(partition_size="100MB").reset_index(drop=True)
     97 print("Repartitioning")
     98 with ProgressBar():

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/dataframe/core.py:1594, in _Frame.repartition(self, divisions, npartitions, partition_size, freq, force)
   1588     raise ValueError(
   1589         "Please provide exactly one of ``npartitions=``, ``freq=``, "
   1590         "``divisions=``, ``partition_size=`` keyword arguments"
   1591     )
   1593 if partition_size is not None:
-> 1594     return repartition_size(self, partition_size)
   1595 elif npartitions is not None:
   1596     return repartition_npartitions(self, npartitions)

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/dataframe/core.py:7804, in repartition_size(df, size)
   7801     size = parse_bytes(size)
   7802 size = int(size)
-> 7804 mem_usages = df.map_partitions(total_mem_usage, deep=True).compute()
   7806 # 1. split each partition that is larger than partition_size
   7807 nsplits = 1 + mem_usages // size

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/base.py:310, in DaskMethodsMixin.compute(self, **kwargs)
    286 def compute(self, **kwargs):
    287     """Compute this dask collection
    288 
    289     This turns a lazy Dask collection into its in-memory equivalent.
   (...)
    308     dask.compute
    309     """
--> 310     (result,) = compute(self, traverse=False, **kwargs)
    311     return result

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/base.py:595, in compute(traverse, optimize_graph, scheduler, get, *args, **kwargs)
    592     keys.append(x.__dask_keys__())
    593     postcomputes.append(x.__dask_postcompute__())
--> 595 results = schedule(dsk, keys, **kwargs)
    596 return repack([f(r, *a) for r, (f, a) in zip(results, postcomputes)])

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/threaded.py:89, in get(dsk, keys, cache, num_workers, pool, **kwargs)
     86     elif isinstance(pool, multiprocessing.pool.Pool):
     87         pool = MultiprocessingPoolExecutor(pool)
---> 89 results = get_async(
     90     pool.submit,
     91     pool._max_workers,
     92     dsk,
     93     keys,
     94     cache=cache,
     95     get_id=_thread_get_id,
     96     pack_exception=pack_exception,
     97     **kwargs,
     98 )
    100 # Cleanup pools associated to dead threads
    101 with pools_lock:

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/local.py:511, in get_async(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)
    509         _execute_task(task, data)  # Re-execute locally
    510     else:
--> 511         raise_exception(exc, tb)
    512 res, worker_id = loads(res_info)
    513 state["cache"][key] = res

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/local.py:319, in reraise(exc, tb)
    317 if exc.__traceback__ is not tb:
    318     raise exc.with_traceback(tb)
--> 319 raise exc

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/local.py:224, in execute_task(key, task_info, dumps, loads, get_id, pack_exception)
    222 try:
    223     task, data = loads(task_info)
--> 224     result = _execute_task(task, data)
    225     id = get_id()
    226     result = dumps((result, id))

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:121, in _execute_task(arg, cache, dsk)
    117     func, args = arg[0], arg[1:]
    118     # Note: Don't assign the subtask results to a variable. numpy detects
    119     # temporaries by their reference count and can execute certain
    120     # operations in-place.
--> 121     return func(*(_execute_task(a, cache) for a in args))
    122 elif not ishashable(arg):
    123     return arg

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/optimization.py:992, in SubgraphCallable.__call__(self, *args)
    990 if not len(args) == len(self.inkeys):
    991     raise ValueError("Expected %d args, got %d" % (len(self.inkeys), len(args)))
--> 992 return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:151, in get(dsk, out, cache)
    149 for key in toposort(dsk):
    150     task = dsk[key]
--> 151     result = _execute_task(task, cache)
    152     cache[key] = result
    153 result = _execute_task(out, cache)

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:121, in _execute_task(arg, cache, dsk)
    117     func, args = arg[0], arg[1:]
    118     # Note: Don't assign the subtask results to a variable. numpy detects
    119     # temporaries by their reference count and can execute certain
    120     # operations in-place.
--> 121     return func(*(_execute_task(a, cache) for a in args))
    122 elif not ishashable(arg):
    123     return arg

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:121, in (.0)
    117     func, args = arg[0], arg[1:]
    118     # Note: Don't assign the subtask results to a variable. numpy detects
    119     # temporaries by their reference count and can execute certain
    120     # operations in-place.
--> 121     return func(*(_execute_task(a, cache) for a in args))
    122 elif not ishashable(arg):
    123     return arg

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:115, in _execute_task(arg, cache, dsk)
     85 """Do the actual work of collecting data and executing a function
     86 
     87 Examples
   (...)
    112 'foo'
    113 """
    114 if isinstance(arg, list):
--> 115     return [_execute_task(a, cache) for a in arg]
    116 elif istask(arg):
    117     func, args = arg[0], arg[1:]

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:115, in (.0)
     85 """Do the actual work of collecting data and executing a function
     86 
     87 Examples
   (...)
    112 'foo'
    113 """
    114 if isinstance(arg, list):
--> 115     return [_execute_task(a, cache) for a in arg]
    116 elif istask(arg):
    117     func, args = arg[0], arg[1:]

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:121, in _execute_task(arg, cache, dsk)
    117     func, args = arg[0], arg[1:]
    118     # Note: Don't assign the subtask results to a variable. numpy detects
    119     # temporaries by their reference count and can execute certain
    120     # operations in-place.
--> 121     return func(*(_execute_task(a, cache) for a in args))
    122 elif not ishashable(arg):
    123     return arg

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:121, in (.0)
    117     func, args = arg[0], arg[1:]
    118     # Note: Don't assign the subtask results to a variable. numpy detects
    119     # temporaries by their reference count and can execute certain
    120     # operations in-place.
--> 121     return func(*(_execute_task(a, cache) for a in args))
    122 elif not ishashable(arg):
    123     return arg

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:115, in _execute_task(arg, cache, dsk)
     85 """Do the actual work of collecting data and executing a function
     86 
     87 Examples
   (...)
    112 'foo'
    113 """
    114 if isinstance(arg, list):
--> 115     return [_execute_task(a, cache) for a in arg]
    116 elif istask(arg):
    117     func, args = arg[0], arg[1:]

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:115, in (.0)
     85 """Do the actual work of collecting data and executing a function
     86 
     87 Examples
   (...)
    112 'foo'
    113 """
    114 if isinstance(arg, list):
--> 115     return [_execute_task(a, cache) for a in arg]
    116 elif istask(arg):
    117     func, args = arg[0], arg[1:]

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:121, in _execute_task(arg, cache, dsk)
    117     func, args = arg[0], arg[1:]
    118     # Note: Don't assign the subtask results to a variable. numpy detects
    119     # temporaries by their reference count and can execute certain
    120     # operations in-place.
--> 121     return func(*(_execute_task(a, cache) for a in args))
    122 elif not ishashable(arg):
    123     return arg

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:121, in (.0)
    117     func, args = arg[0], arg[1:]
    118     # Note: Don't assign the subtask results to a variable. numpy detects
    119     # temporaries by their reference count and can execute certain
    120     # operations in-place.
--> 121     return func(*(_execute_task(a, cache) for a in args))
    122 elif not ishashable(arg):
    123     return arg

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:121, in _execute_task(arg, cache, dsk)
    117     func, args = arg[0], arg[1:]
    118     # Note: Don't assign the subtask results to a variable. numpy detects
    119     # temporaries by their reference count and can execute certain
    120     # operations in-place.
--> 121     return func(*(_execute_task(a, cache) for a in args))
    122 elif not ishashable(arg):
    123     return arg

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:121, in (.0)
    117     func, args = arg[0], arg[1:]
    118     # Note: Don't assign the subtask results to a variable. numpy detects
    119     # temporaries by their reference count and can execute certain
    120     # operations in-place.
--> 121     return func(*(_execute_task(a, cache) for a in args))
    122 elif not ishashable(arg):
    123     return arg

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:115, in _execute_task(arg, cache, dsk)
     85 """Do the actual work of collecting data and executing a function
     86 
     87 Examples
   (...)
    112 'foo'
    113 """
    114 if isinstance(arg, list):
--> 115     return [_execute_task(a, cache) for a in arg]
    116 elif istask(arg):
    117     func, args = arg[0], arg[1:]

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:115, in (.0)
     85 """Do the actual work of collecting data and executing a function
     86 
     87 Examples
   (...)
    112 'foo'
    113 """
    114 if isinstance(arg, list):
--> 115     return [_execute_task(a, cache) for a in arg]
    116 elif istask(arg):
    117     func, args = arg[0], arg[1:]

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:121, in _execute_task(arg, cache, dsk)
    117     func, args = arg[0], arg[1:]
    118     # Note: Don't assign the subtask results to a variable. numpy detects
    119     # temporaries by their reference count and can execute certain
    120     # operations in-place.
--> 121     return func(*(_execute_task(a, cache) for a in args))
    122 elif not ishashable(arg):
    123     return arg

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:121, in (.0)
    117     func, args = arg[0], arg[1:]
    118     # Note: Don't assign the subtask results to a variable. numpy detects
    119     # temporaries by their reference count and can execute certain
    120     # operations in-place.
--> 121     return func(*(_execute_task(a, cache) for a in args))
    122 elif not ishashable(arg):
    123     return arg

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/core.py:121, in _execute_task(arg, cache, dsk)
    117     func, args = arg[0], arg[1:]
    118     # Note: Don't assign the subtask results to a variable. numpy detects
    119     # temporaries by their reference count and can execute certain
    120     # operations in-place.
--> 121     return func(*(_execute_task(a, cache) for a in args))
    122 elif not ishashable(arg):
    123     return arg

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/dataframe/io/parquet/core.py:96, in ParquetFunctionWrapper.__call__(self, part)
     93 if not isinstance(part, list):
     94     part = [part]
---> 96 return read_parquet_part(
     97     self.fs,
     98     self.engine,
     99     self.meta,
    100     [
    101         # Temporary workaround for HLG serialization bug
    102         # (see: https://github.com/dask/dask/issues/8581)
    103         (p.data["piece"], p.data.get("kwargs", {}))
    104         if hasattr(p, "data")
    105         else (p["piece"], p.get("kwargs", {}))
    106         for p in part
    107     ],
    108     self.columns,
    109     self.index,
    110     self.common_kwargs,
    111 )

File ~/.conda/envs/firelab/lib/python3.9/site-packages/dask/dataframe/io/parquet/core.py:657, in read_parquet_part(fs, engine, meta, part, columns, index, kwargs)
    654 if len(part) == 1 or part[0][1] or not check_multi_support(engine):
    655     # Part kwargs expected
    656     func = engine.read_partition
--> 657     dfs = [
...
   5938     raise KeyError(f"None of [{key}] are in the [{axis_name}]")
   5940 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique())
-> 5941 raise KeyError(f"{not_found} not in index")

KeyError: "['dm_tmin', 'unique_id', 'dm_tmax', 'Event_ID'] not in index"